# mPLUG: Effective and Efficient Vision-Language Learning by Cross-modal Skip-connections

[https://arxiv.org/abs/2205.12005](https://arxiv.org/abs/2205.12005)
                      
## Model Overview

mPLUG is a unified vision-language foundation model for both cross-modal understanding and generation. Key features:

- Novel cross-modal skip-connections architecture for effective and efficient vision-language learning
- State-of-the-art performance on multiple vision-language tasks
- Strong zero-shot transfer ability to video-language tasks

## Installation

```bash
git clone https://github.com/username/mplug.git
cd mplug
pip install -r requirements.txt
```


### Pre-training

To pre-train mPLUG


### Fine-tuning

To fine-tune on downstream tasks


### Evaluation

To evaluate on downstream tasks
